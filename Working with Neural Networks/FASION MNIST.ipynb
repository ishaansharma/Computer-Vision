{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 11us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 12s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 1us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 3s 1us/step\n",
      "Nb Train: 60000 Nb test: 10000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        18432     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36864     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         73728     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 287,402\n",
      "Trainable params: 287,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 515s 9ms/step - loss: 0.4616 - acc: 0.8317 - val_loss: 0.3338 - val_acc: 0.8811\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 416s 7ms/step - loss: 0.2814 - acc: 0.8977 - val_loss: 0.2610 - val_acc: 0.9067\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 380s 6ms/step - loss: 0.2293 - acc: 0.9168 - val_loss: 0.2592 - val_acc: 0.9094\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 382s 6ms/step - loss: 0.2006 - acc: 0.9253 - val_loss: 0.2333 - val_acc: 0.9173\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 381s 6ms/step - loss: 0.1714 - acc: 0.9368 - val_loss: 0.2402 - val_acc: 0.9169\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 381s 6ms/step - loss: 0.1499 - acc: 0.9446 - val_loss: 0.2310 - val_acc: 0.9165\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 381s 6ms/step - loss: 0.1298 - acc: 0.9518 - val_loss: 0.2382 - val_acc: 0.9203\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 381s 6ms/step - loss: 0.1101 - acc: 0.9586 - val_loss: 0.2378 - val_acc: 0.9246\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 772s 13ms/step - loss: 0.0955 - acc: 0.9641 - val_loss: 0.2568 - val_acc: 0.9252\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 13301s 222ms/step - loss: 0.0818 - acc: 0.9694 - val_loss: 0.2675 - val_acc: 0.9202\n",
      "Test loss: 0.267468971117\n",
      "Test accuracy: 0.9202\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Conv2D, Input, MaxPooling2D, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# setup parameters\n",
    "batch_sz = 64 \n",
    "nb_class = 10 \n",
    "nb_epochs = 10 \n",
    "img_h, img_w = 28, 28 \n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    \"\"\"\n",
    "    Return processed and reshaped dataset for training\n",
    "    In this cases Fashion-mnist dataset.\n",
    "    \"\"\"\n",
    "    # load mnist dataset\n",
    "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "    \n",
    "    # test and train datasets\n",
    "    print(\"Nb Train:\", x_train.shape[0], \"Nb test:\",x_test.shape[0])\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_h, img_w, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_h, img_w, 1)\n",
    "    in_shape = (img_h, img_w, 1)\n",
    "\n",
    "    # normalize inputs\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255.0\n",
    "    x_test /= 255.0\n",
    "\n",
    "    # convert to one hot vectors \n",
    "    y_train = keras.utils.to_categorical(y_train, nb_class)\n",
    "    y_test = keras.utils.to_categorical(y_test, nb_class)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_dataset()\n",
    "\n",
    "def conv3x3(input_x,nb_filters):\n",
    "    \"\"\"\n",
    "    Wrapper around convolution layer\n",
    "    Inputs:\n",
    "        input_x: input layer / tensor\n",
    "        nb_filter: Number of filters for convolution\n",
    "    \"\"\"\n",
    "    return Conv2D(nb_filters, kernel_size=(3,3), use_bias=False,\n",
    "               activation='relu', padding=\"same\")(input_x)\n",
    "\n",
    "def create_model(img_h=28, img_w=28):\n",
    "    \"\"\"\n",
    "    Creates a CNN model for training. \n",
    "    Inputs: \n",
    "        img_h: input image height\n",
    "        img_w: input image width\n",
    "    Returns:\n",
    "        Model structure \n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = Input(shape=(img_h, img_w, 1))\n",
    "\n",
    "    x = conv3x3(inputs, 32)\n",
    "    x = conv3x3(x, 32)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x) \n",
    "    x = conv3x3(x, 64)\n",
    "    x = conv3x3(x, 64)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x) \n",
    "    x = conv3x3(x, 128)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x) \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    preds = Dense(nb_class, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=preds)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "# setup optimizer, loss function and metrics for model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# To save model after each epoch of training\n",
    "callback = ModelCheckpoint('mnist_cnn.h5')\n",
    "\n",
    "# start training\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_sz,\n",
    "          epochs=nb_epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[callback])\n",
    "\n",
    "# Evaluate and print accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
